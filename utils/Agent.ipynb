{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state\n",
    "class IQAState(TypedDict):\n",
    "    task: str\n",
    "    course_structure: str\n",
    "    evaluation_methods: List[str]\n",
    "    evaluation_level: str\n",
    "    content: List[str]\n",
    "    framework_results: List[dict]\n",
    "    final_summary: str\n",
    "    evaluation_round: int\n",
    "    max_rounds: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "CONFIRMATION_PROMPT = \"\"\"You are an instructional quality evaluator. \n",
    "The user has uploaded a course with the following structure and categories:\n",
    "{course_structure}\n",
    "\n",
    "Please confirm if the uploaded content matches the expected scope of the course. \n",
    "Confirm the categories and any files (e.g., PDFs, videos, audio) in the course package. \n",
    "If there are discrepancies or missing files, ask the user to re-upload the content or correct the errors.\"\"\"\n",
    "\n",
    "EVALUATION_FRAMEWORKS_PROMPT = \"\"\"You are an instructional design expert.\n",
    "Based on the course provided by the user, suggest one or two proven frameworks or methods that will be used to evaluate the instructional quality of the course. \n",
    "Make sure to provide a clear description of each framework and explain how it applies to the specific course content and its goals.\"\"\"\n",
    "\n",
    "DEPTH_ACCURACY_PROMPT = \"\"\"You are an instructional quality evaluator. \n",
    "Ask the user the level of depth and accuracy they want from the evaluation. \n",
    "Provide options such as 'Basic Overview', 'In-Depth Analysis', or 'Detailed Critique' and explain what each level means in terms of the feedback they will receive.\"\"\"\n",
    "\n",
    "PROCESS_CONFIRMATION_PROMPT = \"\"\"You are an instructional quality evaluator. \n",
    "The user has selected the following evaluation method(s): \n",
    "{evaluation_methods}\n",
    "\n",
    "Please confirm the process that will be followed and outline any additional steps the user needs to know about.\n",
    "Reassure the user that the evaluation will begin shortly, and they will receive both quantitative ratings and qualitative feedback.\"\"\"\n",
    "\n",
    "REPORT_GENERATION_PROMPT = \"\"\"You are an instructional quality evaluator. \n",
    "Generate a final report for the user based on the course evaluation. \n",
    "The report should include:\n",
    "1. A numerical rating of the overall course quality (0-10 scale).\n",
    "2. Scores for each of the evaluation criteria (e.g., content clarity, instructional methods, engagement, etc.).\n",
    "3. A summary of findings and actionable feedback for improving the course.\n",
    "Ensure that the report is clear, concise, and professional.\"\"\"\n",
    "\n",
    "FEEDBACK_RECOMMENDATIONS_PROMPT = \"\"\"You are an instructional design expert.\n",
    "Based on the evaluation, generate detailed feedback and recommendations for the user to improve their course. \n",
    "Cover aspects such as content structure, clarity, engagement, and instructional design best practices.\n",
    "Provide specific suggestions for each area and prioritize improvements that will have the greatest impact on the course quality.\"\"\"\n",
    "\n",
    "FOLLOWUP_EVALUATION_PROMPT = \"\"\"You are an instructional quality evaluator.\n",
    "The user has revised their course based on your initial feedback.\n",
    "Evaluate the updated course by applying the same criteria and frameworks used in the first evaluation.\n",
    "Provide a comparison of the original and updated versions and comment on any improvements or areas still needing attention.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from file_processor import FileProcessor\n",
    "\n",
    "file_processor = FileProcessor()\n",
    "\n",
    "load_doc = file_processor.load_pdf(\"files/RFP DATA CENTER.doc-1.pdf\")\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Area-51m\\anaconda3\\envs\\evaToolEnv\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "map_prompt = hub.pull(\"rlm/map-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also available via the hub: `hub.pull(\"rlm/reduce-prompt\")`\n",
    "reduce_template = \"\"\"\n",
    "The following is a set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary\n",
    "of the main themes.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 67 documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "split_docs = text_splitter.split_documents(load_doc)\n",
    "print(f\"Generated {len(split_docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ministry of Information, Communication and Information Technology of the United Republic of Tanzania has issued a Request for Proposal (RFP) for consultancy services to establish a Tier-III Data Center in Zanzibar. This initiative is part of the government's efforts to enhance ICT infrastructure, promote citizen participation, and facilitate e-services. The RFP invites proposals from shortlisted consulting firms to conduct a feasibility study, design the data center, and provide technical specifications, including a Bill of Quantities (BoQ) and estimated budget.\n",
      "\n",
      "Key objectives include assessing current data center needs, ensuring the architectural and environmental integrity of the proposed facility, and providing recommendations for project management and a suitable business model. The consultancy work is expected to span four months, and firms will be evaluated based on their technical and financial proposals under a Quality and Cost Based Selection (QCBS) method.\n",
      "\n",
      "The RFP outlines the qualifications required for consultant personnel, the scope of services, deliverables, and submission details. It emphasizes compliance with local laws and regulations, as well as adherence to ethical standards, including anti-bribery policies. The deadline for proposal submission is set for February 21, 2023, and further details can be found in the accompanying documents within the RFP.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",
    ")\n",
    "\n",
    "# Instantiate chain\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Invoke chain\n",
    "result = chain.invoke({\"context\": split_docs})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaToolEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
